---
title: "SCEM Assignment 7"
author: "Max Kirwan"
date: "17/11/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
```{r}
library(tidyverse)
```


## 1. Student's t-confidence intervals

If the sample mean were higher, the width of the confidence interval would not change. <br>
However if the sample standard deviation were higher, the width of the confidence interval would increase. <br>
If the sample size were larger, but the sample mean and sample standard deviation were to stay the same, then the width of the confidence interval would decrease.

```{r}
library(Stat2Data)
data("Hawks")
RT_weights <- Hawks %>% filter(Species=="RT") %>% select(Weight) %>% na.omit()
RT_weights_vec <- pull(RT_weights)

# Using Student's t-method to compute 99%-level confidence intervals for the population mean
alpha <- 0.01
n <- length(RT_weights_vec)
sample_mean <- mean(RT_weights_vec)
sample_sd <- sd(RT_weights_vec)
t <- qt(1-alpha/2,df=n-1)
lower <- sample_mean-t*sample_sd/sqrt(n)
upper <- sample_mean+t*sample_sd/sqrt(n)
confidence_interval <- c(lower,upper)
confidence_interval
```
Here we are making the assumption that our data has a Gaussian distribution. <br>
Let's check whether this assumption is justified.

```{r}
ggplot(data=RT_weights,aes(x=Weight)) + geom_density()
```
```{r}
ggplot(data=RT_weights, aes(sample=Weight)) + stat_qq() + stat_qq_line() + labs(x="Theoretical",y="Sample")
```

## 2. One sample t-test

Here we are carrying out a statistical hypothesis test to test the hypothesis that the mean bill length of the Adelie penguins is 40mm. <br>
Our null hypothesis is $H_0$: $\mu = 40$. <br>
Our alternative hypothesis is $H_0$: $\mu \ne 40$. <br>
We choose a significance level of $0.01$.
```{r}
library(palmerpenguins)
bill_adelie <- penguins %>% filter(species=="Adelie") %>% select(bill_length_mm) %>% na.omit()
bill_adelie_vec <- pull(bill_adelie)

t.test(bill_adelie_vec,mu=40)
```
Since the p-value is less than our significance level, $p=0.0000001114 < 0.01 = \alpha$, then we reject the null hypothesis $H_0$ and accept $H_1$: $\mu \ne 40$.

Again, here we are assuming that our data has a Gaussian distribution.
Let's check whether this assumption is justified.

```{r}
ggplot(data=bill_adelie,aes(x=bill_length_mm)) + geom_density()
```
```{r}
ggplot(data=bill_adelie, aes(sample=bill_length_mm)) + stat_qq() + stat_qq_line() + labs(x="Theoretical",y="Sample")
```


## 3. Implementing a one sample t-test

```{r}
# Here we are implementing a function which carries out a two-sided one sample t-test
t_test <- function(x,mu_0){
  x <- na.omit(x) # remove any NAs
  n <- length(x)
  sample_mean <- mean(x)
  sample_sd <- sd(x)
  test_statistic <- (sample_mean-mu_0)/(sample_sd/sqrt(n))
  p_value <- 2*(1-pt(abs(test_statistic),df=n-1))
  return(p_value)
}
t_test(bill_adelie_vec,40)
```


## 4. The paired t-test

Here we are carrying out a paired t-test to determine whether there is a difference in average yield between the two types of barley. <br>
Our null hypothesis is $H_0$: $\mu = 0$. <br>
Our alternative hypothesis is $H_0$: $\mu \ne 0$.<br>
We choose a significance level of $0.01$.

```{r}
library(PairedData)
data("Barley")

Barley_diffs <- Barley %>% mutate(diff=Glabron-Velvet)
diffs_vec <- Barley_diffs %>% pull(diff)
t_test(diffs_vec,0) # Using my t test function to calculate p-value
t.test(x=Barley$Glabron,y=Barley$Velvet,paired=1) # Using in-built t.test function
```

The p-value is greater than our significance level, $p=0.0118 > 0.01 = \alpha$. <br>
Therefore we accept the null hypothesis $H_0$. <br>

Here we are assuming that the yields of the different types of barley are independent.

```{r}
# Calculating the effect size using Cohen's d statistic
effect_size <- mean(diffs_vec)/sd(diffs_vec)
effect_size
```

Since the effect size is greater than 0.8 we say that we have a large effect.


## 5. Investigating coverage for Student's t intervals

```{r}
student_t_confidence_interval <- function(sample,confidence_level){
  sample <- sample[!is.na(sample)] # remove any missing values
  n <- length(sample) # compute sample size
  mu_est <- mean(sample) # compute sample mean
  sig_est <- sd(sample) # compute sample sd
  alpha <- 1-confidence_level # alpha from gamma
  t <- qt(1-alpha/2,df=n-1) # get student t quantile
  l <- mu_est-(t/sqrt(n))*sig_est # lower
  u <- mu_est+(t/sqrt(n))*sig_est # upper
  return(c(l,u))
}
```

```{r}
num_trials <- 10000
sample_size <- 30
mu_0 <- 1
sigma_0 <- 3
alpha <- 0.05

set.seed(0) # set random seed for reproducibility
single_alpha_coverage_simulation_df <- crossing(gamma=seq(0.5,0.95,0.05),trial=seq(num_trials)) %>%
  mutate(sample=map(.x=trial,.f=~rnorm(n=sample_size,mean=mu_0,sd=sigma_0))) %>%
  # generate random Gaussian samples
  mutate(ci_interval=map2(.x=gamma,.y=sample,.f=~student_t_confidence_interval(.y,.x))) %>%
  # generate confidence intervals
  mutate(cover=map_lgl(.x=ci_interval,.f=~((min(.x)<=mu_0)&(max(.x)>=mu_0)))) %>%
  # check if interval covers mu_0
  mutate(ci_length=map_dbl(.x=ci_interval, .f=~(max(.x)-min(.x))))
  # compute interval length

cover_means <- single_alpha_coverage_simulation_df %>% group_by(gamma) %>% summarise(mean(cover))
ci_length_means <- single_alpha_coverage_simulation_df %>% group_by(gamma) %>% summarise(ci_length=mean(ci_length))

cover_means

ci_length_means
ggplot(ci_length_means,aes(x=gamma,y=ci_length)) + geom_line() + labs(x="Confidence level",y="Length of confidence interval")
```
We can see that as the confidence level increases, the average length of the confidence interval increases.

## 6. Wilson's confidence interval for proportions

Using Wilson's method to compute the $99\%$ confidence interval for the pass rate of a driving test.
```{r}
library(PropCIs)
driving_test_results <- c(1,0,1,0,0,0,0,0,0,1,0,0,0,1,0,1,0,1,0,1,0,0,1,0)
alpha <- 0.01 # failure probability
num_successes <- sum(driving_test_results) # total passes
sample_size <- length(driving_test_results)
scoreci(x=num_successes, n=sample_size, conf.level=1-alpha) # compute Wilson's confidence intervals
```

Using Wilson's method to compute a 95% confidence interval for the proportion of red-tailed hawks who weigh more than a kilogram.
```{r}
over_1kg <- function(x){
  if(x>1000){return(1)}
  else{return(0)}
}

over_1kg_list <- RT_weights %>% mutate(over_1kg=map_dbl(.x=Weight,.f=~over_1kg(.x))) %>% pull(over_1kg)
print(mean(over_1kg_list))
scoreci(x=sum(over_1kg_list), n=length(over_1kg_list), conf.level=0.95)
```


## 7. The Binomial test

We shall carry out a statistical hypothesis test to test the hypothesis that $87.5\%$ of the arrivals of flights with the Delta airline at the Oâ€™Hare airport are on time. <br>
Our null hypothesis is $H_0$: $q = 0.875$. <br>
Our alternative hypothesis is $H_0$: $q \ne 0.875$.<br>
We choose a significance level of $0.05$.
```{r}
data("Airlines")
delta_ohare <- Airlines %>% subset(IndOHare==1 & IndDelta==1)
on_time <- pull(delta_ohare,OnTime)
sample_size <- length(on_time)
num_yes <- length(on_time[on_time=="yes"])
alpha <- 0.05

binom.test(x=num_yes, n=sample_size, p=0.875, alternative="two.sided")
```

Our p-value is greater than our significance level, $p=0.07796 > 0.05 = \alpha$. <br>
Therefore we accept the null hypothesis, $H_0$: $q = 0.875$. <br>
To conduct this hypothesis test we have made the assumption that the arrival times of the flights are independent, which in reality is probably not true (a late flight will likely make other flights late).


## 8. Bootstrap confidence intervals

```{r}
library(boot) # load the library
set.seed(123) # set random seed so that results can be reproduced

# first define a function which computes the mean of a column of interest
compute_mean <- function(df,indicies,col_name){
  sub_sample <- df %>% slice(indicies) %>% pull(all_of(col_name)) # extract subsample
  return(mean(sub_sample,na.rm=1))} # return mean

# use the boot function to generate the bootstrap statistics
results <- boot(data=penguins, statistic=compute_mean, col_name="body_mass_g", R=1000)

# compute the 95%-level confidence interval for the mean
boot.ci(boot.out=results, type="basic", conf=0.95)
```
We use a random seed to be able to reproduce our results, as the bootstrap method uses random sampling.

Here we are assuming that our sample is independent and identically distributed, but we do not make any assumptions about the distribution.

```{r}
set.seed(123) # set random seed so that results can be reproduced

# first define a function which computes the median of a column of interest
compute_median <- function(df,indicies,col_name){
  sub_sample <- df %>% slice(indicies) %>% pull(all_of(col_name)) # extract subsample
  return(median(sub_sample,na.rm=1))} # return median

# use the boot function to generate the bootstrap statistics
results <- boot(data=Hawks, statistic=compute_median, col_name="Weight", R=1000)

# compute the 99%-level confidence interval for the mean
boot.ci(boot.out=results, type="basic", conf=0.99)
```


## 10. Effect size for the one sample t-test

```{r}
effect_size_one_sample_t_test <- function(x,mu){
  sample_mean <- mean(x,na.rm=1)
  sample_sd <- sd(x,na.rm=1)
  return((sample_mean-mu)/sample_sd)
}
effect_size_one_sample_t_test(x=bill_adelie_vec,mu=40)
```

Here we have a moderate effect size for Cohen's d statistic.